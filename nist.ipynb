{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.78      0.64      0.70        11\n",
      "        PwPD       0.50      0.67      0.57         6\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.64      0.65      0.64        17\n",
      "weighted avg       0.68      0.65      0.65        17\n",
      "\n",
      "RFC Confusion Matrix:\n",
      "[[7 4]\n",
      " [2 4]]\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.00      0.00      0.00        11\n",
      "        PwPD       0.35      1.00      0.52         6\n",
      "\n",
      "    accuracy                           0.35        17\n",
      "   macro avg       0.18      0.50      0.26        17\n",
      "weighted avg       0.12      0.35      0.18        17\n",
      "\n",
      "SVM Confusion Matrix:\n",
      "[[ 0 11]\n",
      " [ 0  6]]\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.75      0.55      0.63        11\n",
      "        PwPD       0.44      0.67      0.53         6\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.60      0.61      0.58        17\n",
      "weighted avg       0.64      0.59      0.60        17\n",
      "\n",
      "KNN Confusion Matrix:\n",
      "[[6 5]\n",
      " [2 4]]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.5417 - loss: 1.5998 - val_accuracy: 0.5882 - val_loss: 1.2315\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5417 - loss: 1.1623 - val_accuracy: 0.3529 - val_loss: 2.2394\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5417 - loss: 1.3714 - val_accuracy: 0.3529 - val_loss: 1.5486\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5521 - loss: 1.0464 - val_accuracy: 0.5294 - val_loss: 0.9109\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4792 - loss: 1.0175 - val_accuracy: 0.5294 - val_loss: 0.7696\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6146 - loss: 0.6626 - val_accuracy: 0.4118 - val_loss: 1.1524\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 0.7361 - val_accuracy: 0.3529 - val_loss: 1.0084\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6562 - loss: 0.5826 - val_accuracy: 0.6471 - val_loss: 0.6735\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6354 - loss: 0.6053 - val_accuracy: 0.6471 - val_loss: 0.6584\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6979 - loss: 0.5356 - val_accuracy: 0.4118 - val_loss: 0.8286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.27      0.38        11\n",
      "           1       0.33      0.67      0.44         6\n",
      "\n",
      "    accuracy                           0.41        17\n",
      "   macro avg       0.47      0.47      0.41        17\n",
      "weighted avg       0.51      0.41      0.40        17\n",
      "\n",
      "CNN Confusion Matrix:\n",
      "[[3 8]\n",
      " [2 4]]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import Dropdown, Button, Output, VBox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "from tensorflow.keras import layers, models\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import time\n",
    "import tempfile\n",
    "\n",
    "# Function to display the available files in the directory\n",
    "def list_audio_files(directory):\n",
    "    return [file for file in os.listdir(directory) if file.endswith('.wav')]\n",
    "\n",
    "# Feature extraction function with labeled MFCCs\n",
    "def feature_extraction(file_path):\n",
    "    \"\"\"Extracts MFCC features from an audio file.\"\"\"\n",
    "    # Load the audio file\n",
    "    x, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    \n",
    "    # Extract MFCC features (22 coefficients)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=x, sr=sample_rate, n_mfcc=25).T, axis=0)\n",
    "    \n",
    "    # Label MFCC features (MFCC Coefficient 1, MFCC Coefficient 2, etc.)\n",
    "    mfcc_labels = [f'MFCC_Coefficient_{i+1}' for i in range(len(mfcc))]\n",
    "    return mfcc, mfcc_labels\n",
    "\n",
    "# Directories containing the audio files for Healthy Controls and PwPD\n",
    "hc_directory = r'/Users/tusharshetty/Downloads/HC_AH'    # Update with your HC directory path\n",
    "pwpd_directory = r'/Users/tusharshetty/Downloads/PD_AH 2'     # Update with your PwPD directory path\n",
    "\n",
    "# List all audio files in both directories\n",
    "hc_audio_files = list_audio_files(hc_directory)\n",
    "pwpd_audio_files = list_audio_files(pwpd_directory)\n",
    "\n",
    "# Create an empty DataFrame to store all MFCC features\n",
    "mfcc_df = pd.DataFrame()\n",
    "\n",
    "# Extract features from Healthy Controls\n",
    "for audio_file in hc_audio_files:\n",
    "    audio_path = os.path.join(hc_directory, audio_file)\n",
    "    mfcc_features, mfcc_labels = feature_extraction(audio_path)\n",
    "    temp_df = pd.DataFrame(mfcc_features.reshape(1, -1), columns=mfcc_labels)\n",
    "    temp_df['Audio_File'] = audio_file\n",
    "    temp_df['Label'] = 'HC' \n",
    "    mfcc_df = pd.concat([mfcc_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Extract features from PwPD\n",
    "for audio_file in pwpd_audio_files:\n",
    "    audio_path = os.path.join(pwpd_directory, audio_file)\n",
    "    mfcc_features, mfcc_labels = feature_extraction(audio_path)\n",
    "    temp_df = pd.DataFrame(mfcc_features.reshape(1, -1), columns=mfcc_labels)\n",
    "    temp_df['Audio_File'] = audio_file\n",
    "    temp_df['Label'] = 'PwPD'  \n",
    "    mfcc_df = pd.concat([mfcc_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Prepare data for model training\n",
    "X = mfcc_df.drop(columns=['Audio_File', 'Label'])\n",
    "y = mfcc_df['Label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rfc_model = RandomForestClassifier(random_state=42)\n",
    "rfc_model.fit(X_train, y_train)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_model = SVC(probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Initialize and train the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with all models\n",
    "rfc_pred = rfc_model.predict(X_test)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Print classification reports and confusion matrices\n",
    "print(\"RFC Classification Report:\")\n",
    "print(classification_report(y_test, rfc_pred))\n",
    "\n",
    "print(\"RFC Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rfc_pred))\n",
    "\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_pred))\n",
    "\n",
    "print(\"SVM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, svm_pred))\n",
    "\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, knn_pred))\n",
    "\n",
    "print(\"KNN Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, knn_pred))\n",
    "\n",
    "# Save the trained models\n",
    "joblib.dump(rfc_model, 'rfc_trained_model.joblib')\n",
    "joblib.dump(svm_model, 'svm_trained_model.joblib')\n",
    "joblib.dump(knn_model, 'knn_trained_model.joblib')\n",
    "\n",
    "# Prepare data for CNN\n",
    "X_cnn = X.values.reshape(X.shape[0], X.shape[1], 1)\n",
    "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_cnn, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def build_cnn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Conv1D(32, kernel_size=3, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(layers.Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "cnn_model = build_cnn_model((X_train_cnn.shape[1], 1))\n",
    "cnn_model.fit(X_train_cnn, y_train_cnn.map({'HC': 0, 'PwPD': 1}).values, epochs=10, batch_size=32, validation_data=(X_test_cnn, y_test_cnn.map({'HC': 0, 'PwPD': 1}).values))\n",
    "\n",
    "\n",
    "y_pred_cnn = (cnn_model.predict(X_test_cnn) > 0.5).astype(\"int32\").reshape(-1)\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(y_test_cnn.map({'HC': 0, 'PwPD': 1}), y_pred_cnn))\n",
    "print(\"CNN Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_cnn.map({'HC': 0, 'PwPD': 1}), y_pred_cnn))\n",
    "\n",
    "\n",
    "cnn_model.save('cnn_parkinsons_model.h5')\n",
    "\n",
    "\n",
    "def display_audio_and_classify(audio_file, directory):\n",
    "    audio_path = os.path.join(directory, audio_file)\n",
    "    print(f\"Playing: {audio_file}\")\n",
    "    ipd.display(ipd.Audio(audio_path))\n",
    "    \n",
    "    mfcc_features, mfcc_labels = feature_extraction(audio_path)\n",
    "    mfcc_df_single = pd.DataFrame(mfcc_features.reshape(1, -1), columns=mfcc_labels)\n",
    "    \n",
    "    rfc_prediction = rfc_model.predict(mfcc_df_single)[0]\n",
    "    svm_prediction = svm_model.predict(mfcc_df_single)[0]\n",
    "    knn_prediction = knn_model.predict(mfcc_df_single)[0]\n",
    "    cnn_prediction = (cnn_model.predict(mfcc_df_single.values.reshape(1, -1, 1)) > 0.5).astype(\"int32\")[0][0]\n",
    "\n",
    "    print(f\"Random Forest Prediction for {audio_file}: {'Parkinson Disease (PwPD)' if rfc_prediction == 'PwPD' else 'Healthy Control (HC)'}\")\n",
    "    print(f\"SVM Prediction for {audio_file}: {'Parkinson Disease (PwPD)' if svm_prediction == 'PwPD' else 'Healthy Control (HC)'}\")\n",
    "    print(f\"KNN Prediction for {audio_file}: {'Parkinson Disease (PwPD)' if knn_prediction == 'PwPD' else 'Healthy Control (HC)'}\")\n",
    "    print(f\"CNN Prediction for {audio_file}: {'Parkinson Disease (PwPD)' if cnn_prediction == 1 else 'Healthy Control'}\")\n",
    "\n",
    "\n",
    "audio_dropdown = Dropdown(\n",
    "    options=hc_audio_files + pwpd_audio_files,\n",
    "    description='Select Audio:'\n",
    ")\n",
    "classify_button = Button(description='Classify')\n",
    "output = Output()\n",
    "\n",
    "# Function to record live audio \n",
    "def record_audio(duration=5, sample_rate=22050):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    sd.wait()  # Wait until the recording is finished\n",
    "    print(\"Recording complete.\")\n",
    "    \n",
    "    # Save the audio to a temporary file\n",
    "    temp_file = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "    write(temp_file.name, sample_rate, audio)  # Save as .wav file\n",
    "    return temp_file.name\n",
    "\n",
    "# Button to capture live audio and classify it\n",
    "record_button = Button(description=\"Record and Classify Live Audio\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
